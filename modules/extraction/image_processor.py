"""
MÃ³dulo para procesar URLs de status y convertirlas en URLs de imÃ¡genes directas.
"""
import asyncio
import random
from playwright.async_api import Page
from ..utils.logging import Logger
from ..utils.url_utils import URLUtils
from ..utils.cache_manager import CacheManager

class ImageProcessor:
    """
    Contiene la lÃ³gica para transformar las URLs de los tweets en URLs
    de imÃ¡genes directas y de alta calidad, con cache para optimizar rendimiento.
    """
    def __init__(self, page: Page):
        self.page = page
        self.processed_image_urls: set[str] = set()
        self.username = None
        self.cache_manager = None

    async def convert_status_to_image_urls(self, status_urls: list[dict], username: str = None, url_limit: int = None) -> tuple[list[str], dict]:
        """
        Orquesta la conversiÃ³n de URLs de status a URLs de imÃ¡genes directas
        utilizando mÃºltiples mÃ©todos para maximizar los resultados.
        Usa cache para evitar reprocesamiento innecesario.
        
        Args:
            status_urls: Lista de URLs de status a procesar
            username: Username para el cache
            url_limit: LÃ­mite de URLs nuevas (no cacheadas) a procesar
            
        Returns:
            tuple: (image_urls, url_to_status_mapping)
        """
        # Actualizar username si se proporciona
        if username:
            self.username = username
            self.cache_manager = CacheManager()
        
        Logger.info("ğŸ”„ Iniciando conversiÃ³n de URLs de status a imÃ¡genes directas...")
        
        image_status_urls = [item for item in status_urls if item.get('media_type') == 'image']
        
        # Contar videos para calcular el lÃ­mite correcto de imÃ¡genes
        videos = [item for item in status_urls if item.get('media_type') == 'video']
        total_status = len(status_urls)
        video_count = len(videos)
        expected_images = total_status - video_count  # LÃ­mite dinÃ¡mico basado en status reales
        
        Logger.info(f"ğŸ“Š Se procesarÃ¡n {len(image_status_urls)} URLs de status de tipo imagen.")
        Logger.info(f"ğŸ“Š Status totales: {total_status}, Videos: {video_count}, ImÃ¡genes esperadas: {expected_images}")

        image_urls = []
        new_mappings = {}  # Para actualizar el cache: status_id -> [image_urls]
        
        # Usar cache si estÃ¡ disponible
        if self.cache_manager and self.username:
            cached_urls, uncached_status_urls = self.cache_manager.get_cached_image_urls(
                self.username, image_status_urls
            )
            image_urls.extend(cached_urls)
            image_status_urls = uncached_status_urls
            Logger.info(f"ğŸ’¾ {len(cached_urls)} imÃ¡genes obtenidas del cache")
        
        # Aplicar lÃ­mite a URLs nuevas (no cacheadas) si se especifica
        original_uncached_count = len(image_status_urls)
        if url_limit is not None and len(image_status_urls) > url_limit:
            image_status_urls = image_status_urls[:url_limit]
            Logger.info(f"âš¡ LÃ­mite aplicado: procesando {len(image_status_urls)} de {original_uncached_count} URLs nuevas")
        
        # Extraer username para filtrar correctamente
        target_username = None
        if image_status_urls:
            first_url = image_status_urls[0].get('url', '')
            url_parts = first_url.split('/')
            if len(url_parts) > 3:
                target_username = url_parts[3]  # x.com/username/status/id
        
        Logger.info(f"ğŸ¯ Procesando imÃ¡genes del usuario: @{target_username}")
        
        # Procesar solo las URLs no cacheadas (respetando el lÃ­mite)
        if image_status_urls:
            Logger.info(f"ğŸ”„ Procesando {len(image_status_urls)} URLs nuevas...")
            
            # MÃ‰TODO 1: ExtracciÃ³n desde el DOM (rÃ¡pido y eficiente)
            dom_converted, dom_mappings = await self._extract_from_dom(image_urls, expected_images, image_status_urls, target_username)
            new_mappings.update(dom_mappings)
            
            # MÃ‰TODO 2: ConstrucciÃ³n directa navegando a cada status (mÃ¡s preciso)
            # Solo procesar las URLs que no se pudieron mapear en el mÃ©todo 1
            remaining_unmapped = [url for url in image_status_urls if self._extract_status_id(url.get('url', '')) not in new_mappings]
            
            if remaining_unmapped:
                constructed_count, method2_mappings = await self._construct_direct_urls_improved(
                    remaining_unmapped, image_urls, expected_images, target_username
                )
                new_mappings.update(method2_mappings)
            else:
                constructed_count = 0
            
            # MÃ‰TODO 3: Fallback con extracciÃ³n alternativa si es necesario
            if len(image_urls) < expected_images:
                await self._fallback_image_extraction(image_status_urls, image_urls, expected_images)
            
            # Actualizar cache con nuevos mapeos vÃ¡lidos 
            if self.cache_manager and self.username and new_mappings:
                # Convertir mapeos mÃºltiples a formato de cache (solo primera imagen por status)
                valid_mappings = {}
                for status_id, images in new_mappings.items():
                    if isinstance(images, list) and images:
                        valid_mappings[status_id] = images[0]  # Solo la primera imagen
                    elif isinstance(images, str) and images:
                        valid_mappings[status_id] = images
                
                if valid_mappings:
                    self.cache_manager.update_cache_with_new_mappings(self.username, valid_mappings)
                Logger.info(f"ğŸ’¾ Cache actualizado con {len(valid_mappings)} nuevos mapeos vÃ¡lidos")
        else:
            dom_converted = 0
            constructed_count = 0

        total_converted = len(image_urls)
        total_mappings = sum(len(v) if isinstance(v, list) else 1 for v in new_mappings.values())
        conversion_rate = (total_converted / expected_images * 100) if expected_images else 0
        
        Logger.success(f"ğŸ¯ RESUMEN FINAL:")
        Logger.info(f"   ğŸ’¾ Cache: {len(image_urls) - dom_converted - constructed_count} imÃ¡genes")
        Logger.info(f"   ğŸ” MÃ©todo 1 (DOM): {dom_converted} imÃ¡genes")
        Logger.info(f"   ğŸ”§ MÃ©todo 2 (ConstrucciÃ³n directa): {constructed_count} imÃ¡genes")
        Logger.info(f"   ğŸ“Š Total convertidas: {total_converted}/{expected_images} ({conversion_rate:.1f}%)")
        Logger.info(f"   ğŸ—‚ï¸  Mapeos para cache: {total_mappings} imÃ¡genes mapeadas")
        
        # Mostrar informaciÃ³n sobre lÃ­mite aplicado si corresponde
        if url_limit is not None and original_uncached_count > url_limit:
            Logger.info(f"   âš¡ LÃ­mite aplicado: {url_limit} de {original_uncached_count} URLs nuevas procesadas")
            Logger.info(f"   ğŸ“ Quedaron {original_uncached_count - url_limit} URLs nuevas por procesar")
        
        # Crear mapeo completo de URLs a status_ids - MEJORADO
        complete_mapping = {}
        
        # Agregar mapeos desde cache
        if self.cache_manager and self.username:
            cache_mapping = self.cache_manager.get_url_to_status_mapping(self.username, image_urls)
            complete_mapping.update(cache_mapping)
        
        # Agregar mapeos nuevos - Manejar mÃºltiples imÃ¡genes por status
        for status_id, images in new_mappings.items():
            if isinstance(images, list):
                for image_url in images:
                    if image_url and image_url in image_urls:
                        complete_mapping[image_url] = status_id
            elif isinstance(images, str) and images in image_urls:
                complete_mapping[images] = status_id
        
        # NO crear mapeos adicionales por correlaciÃ³n - esto causaba el problema
        # Solo usar mapeos explÃ­citos y confiables
        unmapped_count = len([url for url in image_urls if url not in complete_mapping])
        if unmapped_count > 0:
            Logger.warning(f"   âš ï¸  {unmapped_count} imÃ¡genes quedarÃ¡n sin status_id especÃ­fico")
            Logger.info(f"   ğŸ’¡ Esto es normal para imÃ¡genes en carruseles mÃºltiples")
        
        return image_urls, complete_mapping

    async def _extract_from_dom(self, image_urls: list[str], expected_images: int, status_urls: list[dict], target_username: str = None) -> tuple[int, dict]:
        """
        MÃ‰TODO 1: Extrae las URLs de las imÃ¡genes directamente desde los elementos <img>
        cargados en la pÃ¡gina y trata de correlacionarlas con status URLs.
        Returns: (dom_converted_count, status_id_to_image_mappings)
        """
        Logger.info("ğŸ” MÃ‰TODO 1: Extrayendo imÃ¡genes desde el DOM...")
        
        # Extraer username del primer status URL para filtrar correctamente si no se proporciona
        if not target_username and status_urls:
            first_url = status_urls[0].get('url', '')
            url_parts = first_url.split('/')
            if len(url_parts) > 3:
                target_username = url_parts[3]  # x.com/username/status/id
        
        Logger.info(f"ğŸ¯ Filtrando imÃ¡genes solo del usuario: @{target_username}")
        
        all_page_images = await self.page.evaluate("""
            (targetUsername) => {
                const images = [];
                const imgElements = document.querySelectorAll('img[src*="pbs.twimg.com"]');
                imgElements.forEach(img => {
                    if (img.src && img.src.includes('pbs.twimg.com') && 
                        !img.src.includes('profile_images') && 
                        !img.src.includes('profile_banners')) {
                        
                        // Obtener el contenedor del tweet para verificar el usuario
                        const tweetContainer = img.closest('article') || img.closest('[data-testid="tweet"]');
                        let belongsToTargetUser = false;
                        
                        if (tweetContainer && targetUsername) {
                            // Buscar enlaces de usuario en el tweet
                            const userLinks = tweetContainer.querySelectorAll('a[href*="/' + targetUsername + '"]');
                            belongsToTargetUser = Array.from(userLinks).some(link => {
                                const href = link.getAttribute('href');
                                return href && href.includes('/' + targetUsername) && !href.includes('/status/');
                            });
                        }
                        
                        images.push({
                            src: img.src,
                            alt: img.alt || '',
                            width: img.naturalWidth || img.width || 0,
                            height: img.naturalHeight || img.height || 0,
                            belongsToTargetUser: belongsToTargetUser,
                            hasContainer: !!tweetContainer
                        });
                    }
                });
                return images;
            }
        """, target_username)
        
        Logger.info(f"   ğŸ“Š Encontradas {len(all_page_images)} imÃ¡genes totales en la pÃ¡gina")
        
        # Filtrar imÃ¡genes que pertenecen al usuario objetivo y parecen ser de tweets
        tweet_images = []
        user_images = [img for img in all_page_images if img.get('belongsToTargetUser', False)]
        Logger.info(f"   ğŸ¯ Filtradas {len(user_images)} imÃ¡genes del usuario @{target_username}")
        
        for img_data in user_images:
            # Filtrar por tamaÃ±o (evitar avatares pequeÃ±os) y verificar que sea del usuario correcto
            if img_data['width'] > 100 and img_data['height'] > 100:
                tweet_images.append(img_data)
            elif img_data['hasContainer']:  # O si estÃ¡ en un contenedor de tweet
                tweet_images.append(img_data)
        
        Logger.info(f"   ğŸ¯ Filtradas {len(tweet_images)} imÃ¡genes que parecen ser de tweets")
        
        # AÃ±adir imÃ¡genes limpias y crear mapeos
        dom_converted = 0
        dom_mappings = {}
        
        for i, img_data in enumerate(tweet_images):
            clean_img_url = URLUtils.clean_image_url_robust(img_data['src'])
            if clean_img_url and clean_img_url not in image_urls:
                # Filtrar thumbnails de video que no son imÃ¡genes reales
                if 'amplify_video_thumb' not in clean_img_url and 'video_thumb' not in clean_img_url:
                    image_urls.append(clean_img_url)
                    dom_converted += 1
                    
                    # Tratar de correlacionar con status URL usando el Ã­ndice o el parent_href
                    if i < len(status_urls):
                        status_id = self._extract_status_id(status_urls[i].get('url', ''))
                        if status_id:
                            dom_mappings[status_id] = clean_img_url
                            Logger.info(f"   âœ… [{i+1}] Imagen DOM mapeada: {status_id} -> {clean_img_url}")
                        else:
                            Logger.info(f"   âœ… [{i+1}] Imagen DOM aÃ±adida: {clean_img_url}")
                    else:
                        Logger.info(f"   âœ… [{i+1}] Imagen DOM aÃ±adida: {clean_img_url}")
                else:
                    Logger.warning(f"   ğŸ¬ Thumbnail de video excluido: {clean_img_url}")
                
                # No limitar artificialmente - permitir mÃºltiples imÃ¡genes por tweet
                # if len(image_urls) >= expected_images:
                #     Logger.warning(f"   ğŸ›‘ LÃ­mite de {expected_images} imÃ¡genes alcanzado")
                #     break
        
        Logger.info(f"   âœ… MÃ©todo 1 completado: {dom_converted} imÃ¡genes aÃ±adidas, {len(dom_mappings)} mapeos creados")
        return dom_converted, dom_mappings

    async def _construct_direct_urls_improved(self, image_status_urls: list[dict], image_urls: list[str], expected_images: int, target_username: str = None) -> tuple[int, dict]:
        """
        MÃ‰TODO 2 MEJORADO: Navegar directamente a cada URL de status para extraer TODAS las imÃ¡genes
        Maneja correctamente carruseles con mÃºltiples imÃ¡genes por tweet
        Returns: (constructed_count, status_to_image_mappings)
        """
        Logger.info(f"   ğŸ”§ MÃ‰TODO 2 MEJORADO: Construyendo URLs directas navegando a {len(image_status_urls)} status...")
        
        constructed_count = 0
        status_mappings = {}  # status_id -> [list_of_image_urls] or single_image_url
        # Usar todas las URLs disponibles - el lÃ­mite ya se aplicÃ³ anteriormente
        remaining_status_urls = image_status_urls  # Procesar todas las URLs que pasaron el filtro de lÃ­mite
        
        for i, item in enumerate(remaining_status_urls, 1):
            try:
                status_url = item.get('url')
                if not status_url:
                    continue
                
                status_id = self._extract_status_id(status_url)
                if not status_id:
                    continue
                
                Logger.info(f"   ğŸ” [{i}/{len(remaining_status_urls)}] Navegando a: {status_url}")
                
                try:
                    await self.page.goto(status_url, wait_until="domcontentloaded", timeout=15000)
                    # Espera orgÃ¡nica despuÃ©s de la navegaciÃ³n para simular tiempo de lectura
                    page_load_delay = random.uniform(1.5, 3.0)
                    await asyncio.sleep(page_load_delay)
                    
                    # Buscar imÃ¡genes SOLO del tweet principal, no de los replies
                    tweet_images = await self.page.evaluate("""
                        (statusUrl) => {
                            const images = [];
                            
                            // Extraer el username del status URL
                            const urlParts = statusUrl.split('/');
                            const expectedUsername = urlParts[3]; // x.com/username/status/id
                            
                            // Buscar especÃ­ficamente el tweet principal (no replies)
                            const tweetContainers = document.querySelectorAll('article, [data-testid="tweet"]');
                            
                            for (const container of tweetContainers) {
                                // Verificar que este tweet pertenece al usuario correcto
                                const userLinks = container.querySelectorAll('a[href*="/' + expectedUsername + '"]');
                                const isMainUser = Array.from(userLinks).some(link => {
                                    const href = link.getAttribute('href');
                                    return href && href.includes('/' + expectedUsername) && !href.includes('/status/');
                                });
                                
                                // Solo procesar si es del usuario correcto
                                if (isMainUser) {
                                    const imgElements = container.querySelectorAll('img[src*="pbs.twimg.com"]');
                                    imgElements.forEach(img => {
                                        if (img.src && 
                                            !img.src.includes('profile_images') && 
                                            !img.src.includes('profile_banners') &&
                                            !img.src.includes('amplify_video_thumb') &&
                                            !img.src.includes('video_thumb') &&
                                            img.width > 100 && img.height > 100) {
                                            images.push({
                                                src: img.src,
                                                username: expectedUsername,
                                                isMainTweet: true
                                            });
                                        }
                                    });
                                }
                            }
                            
                            // Eliminar duplicados y devolver solo las URLs
                            const uniqueImages = [...new Set(images.map(img => img.src))];
                            return uniqueImages;
                        }
                    """, status_url)
                    
                    if tweet_images:
                        status_image_list = []
                        
                        # Procesar TODAS las imÃ¡genes encontradas en el tweet (carruseles)
                        for img_index, img_src in enumerate(tweet_images):
                            clean_img_url = URLUtils.clean_image_url_robust(img_src)
                            
                            if clean_img_url:
                                # Verificar duplicados comparando la base de la URL (sin parÃ¡metros)
                                is_duplicate = self._is_duplicate_image(clean_img_url, image_urls)
                                
                                if not is_duplicate:
                                    image_urls.append(clean_img_url)
                                    status_image_list.append(clean_img_url)
                                    constructed_count += 1
                                    Logger.info(f"   âœ… [{i}/{len(remaining_status_urls)}] URL construida #{img_index+1}: {clean_img_url}")
                                else:
                                    Logger.info(f"   ğŸ’¾ [{i}/{len(remaining_status_urls)}] URL ya existe #{img_index+1}: {clean_img_url}")
                                    # AÃºn aÃ±adir a la lista del status para mapeo correcto
                                    if clean_img_url in image_urls:
                                        status_image_list.append(clean_img_url)
                        
                        # Guardar mapeo completo para este status (todas las imÃ¡genes del usuario correcto)
                        if status_image_list:
                            if len(status_image_list) == 1:
                                status_mappings[status_id] = status_image_list[0]  # String para una sola imagen
                            else:
                                status_mappings[status_id] = status_image_list  # Lista para mÃºltiples imÃ¡genes
                            
                            Logger.info(f"   ğŸ“¸ [{i}/{len(remaining_status_urls)}] Status {status_id} mapeado a {len(status_image_list)} imagen(es) del usuario correcto")
                        else:
                            Logger.warning(f"   âš ï¸  [{i}/{len(remaining_status_urls)}] No se encontraron imÃ¡genes del usuario @{target_username} en este status")
                        
                except Exception as e:
                    Logger.error(f"   âŒ [{i}/{len(remaining_status_urls)}] Error navegando a {status_url}: {e}")
                    continue
                    
            except Exception as e:
                Logger.error(f"   âŒ [{i}/{len(remaining_status_urls)}] Error procesando {item.get('url', 'unknown')}: {e}")
                continue
                
            # Pausa orgÃ¡nica entre navegaciones para simular comportamiento humano
            if i < len(remaining_status_urls):
                delay = self._get_organic_delay()
                Logger.info(f"   â±ï¸  Pausa orgÃ¡nica: {delay:.2f}s antes de la siguiente URL")
                await asyncio.sleep(delay)
        
        Logger.info(f"   âœ… MÃ©todo 2 mejorado: {constructed_count} imÃ¡genes construidas directamente")
        Logger.info(f"   ğŸ“¸ Se mapearon {len(status_mappings)} status con sus imÃ¡genes correspondientes")
        return constructed_count, status_mappings

    def _get_organic_delay(self, base_delay: float = 1.5) -> float:
        """
        Calcula un tiempo de espera orgÃ¡nico y aleatorio para simular comportamiento humano.
        
        Args:
            base_delay: Tiempo base en segundos (por defecto 1.5s)
            
        Returns:
            Tiempo de espera en segundos con variaciÃ³n aleatoria
        """
        # VariaciÃ³n aleatoria del Â±40% del tiempo base
        variation = random.uniform(-0.4, 0.6)  # -40% a +60% para mayor naturalidad
        delay = base_delay * (1 + variation)
        
        # Asegurar que estÃ© dentro del rango deseado (1.0 - 2.5 segundos)
        delay = max(1.0, min(2.5, delay))
        
        # Ocasionalmente agregar pausas mÃ¡s largas (5% de probabilidad)
        if random.random() < 0.05:
            delay += random.uniform(1.0, 3.0)  # Pausa larga ocasional
            Logger.info(f"   â±ï¸  Aplicando pausa larga: {delay:.2f}s")
        
        return delay

    def _extract_status_id(self, status_url: str) -> str:
        """Extrae el ID del status desde la URL."""
        try:
            return status_url.split('/status/')[-1].split('?')[0].split('/')[0]
        except Exception:
            return ""

    def _create_correlation_mappings(self, image_urls: list, status_urls: list, existing_mapping: dict):
        """
        MÃ‰TODO DESACTIVADO: Este mÃ©todo causaba mapeos incorrectos.
        La correlaciÃ³n por orden no es confiable cuando hay carruseles de mÃºltiples imÃ¡genes.
        """
        Logger.info(f"   âš ï¸  MÃ©todo de correlaciÃ³n desactivado para evitar mapeos incorrectos")
        Logger.info(f"   ğŸ’¡ Solo se usan mapeos explÃ­citos obtenidos de navegaciÃ³n directa")
        return 0
    
    def _is_duplicate_image(self, new_url: str, existing_urls: list[str]) -> bool:
        """
        Verifica si una URL de imagen ya existe en la lista.
        Compara la base de la imagen (sin parÃ¡metros) para detectar duplicados.
        """
        try:
            # Extraer la parte base de la nueva URL (sin parÃ¡metros)
            new_base = new_url.split('?')[0] if '?' in new_url else new_url
            
            for existing_url in existing_urls:
                # Extraer la parte base de la URL existente
                existing_base = existing_url.split('?')[0] if '?' in existing_url else existing_url
                
                # Comparar las bases
                if new_base == existing_base:
                    return True
                    
            return False
        except Exception:
            return False

    async def _fallback_image_extraction(self, image_status_urls: list[dict], image_urls: list[str], expected_images: int):
        """
        MÃ‰TODO 3: Fallback con extracciÃ³n alternativa
        """
        Logger.info("   ğŸ”„ MÃ‰TODO 3: Fallback con extracciÃ³n alternativa...")
        
        # Obtener todas las imÃ¡genes disponibles en la pÃ¡gina con mÃ¡s contexto
        all_page_images = await self.page.evaluate("""
            () => {
                const images = [];
                const imgElements = document.querySelectorAll('img[src*="pbs.twimg.com"]');
                imgElements.forEach(img => {
                    if (img.src && img.src.includes('pbs.twimg.com') && 
                        !img.src.includes('profile_images') && 
                        !img.src.includes('profile_banners')) {
                        
                        // Obtener mÃ¡s contexto sobre la imagen
                        const parentLink = img.closest('a');
                        const tweetContainer = img.closest('article') || img.closest('[data-testid="tweet"]');
                        
                        images.push({
                            src: img.src,
                            alt: img.alt || '',
                            parent_href: parentLink ? parentLink.href : null,
                            has_tweet_container: !!tweetContainer,
                            width: img.naturalWidth || img.width || 0,
                            height: img.naturalHeight || img.height || 0
                        });
                    }
                });
                return images;
            }
        """)
        
        Logger.info(f"   ğŸ“Š Encontradas {len(all_page_images)} imÃ¡genes totales en la pÃ¡gina")
        
        # Filtrar imÃ¡genes que parecen ser de tweets (no avatares pequeÃ±os)
        tweet_images = []
        for img_data in all_page_images:
            # Filtrar por tamaÃ±o (evitar avatares pequeÃ±os)
            if img_data['width'] > 100 and img_data['height'] > 100:
                tweet_images.append(img_data)
            elif img_data['has_tweet_container']:  # O si estÃ¡ en un contenedor de tweet
                tweet_images.append(img_data)
        
        Logger.info(f"   ğŸ¯ Filtradas {len(tweet_images)} imÃ¡genes que parecen ser de tweets")
        
        # AÃ±adir imÃ¡genes que no estÃ©n ya en la lista
        added_count = 0
        for img_data in tweet_images:
            clean_img_url = URLUtils.clean_image_url_robust(img_data['src'])
            if clean_img_url and clean_img_url not in image_urls:
                # Filtrar thumbnails de video que no son imÃ¡genes reales
                if 'amplify_video_thumb' not in clean_img_url and 'video_thumb' not in clean_img_url:
                    image_urls.append(clean_img_url)
                    added_count += 1
                    Logger.info(f"   â• Imagen alternativa aÃ±adida: {clean_img_url}")
                else:
                    Logger.warning(f"   ğŸ¬ Thumbnail de video excluido: {clean_img_url}")
                
                # No limitar artificialmente - permitir mÃºltiples imÃ¡genes por tweet
                # if len(image_urls) >= expected_images:
                #     Logger.warning(f"   ğŸ›‘ LÃ­mite de {expected_images} imÃ¡genes alcanzado")
                #     break
        
        Logger.info(f"   âœ… MÃ©todo alternativo aÃ±adiÃ³ {added_count} imÃ¡genes adicionales")