#!/usr/bin/env python3
"""
Script optimizado para Microsoft Edge con descarga de im√°genes de X
Autor: Asistente AI
Fecha: 11 de junio de 2025

Este script est√° espec√≠ficamente dise√±ado para usar Microsoft Edge
donde ya tienes sesi√≥n iniciada en X, y maneja autom√°ticamente
la verificaci√≥n de login y navegaci√≥n.

FUNCIONALIDAD: Solo descarga IM√ÅGENES de la secci√≥n Media.
Para videos, usa x_video_url_extractor.py que extrae las URLs en JSON.

NUEVA FUNCIONALIDAD:
- Soporte para m√∫ltiples usuarios configurados en x_usernames.json
- Par√°metro --name para seleccionar usuario por nombre amigable
- Configuraci√≥n autom√°tica de directorios personalizados por usuario
"""

import os
import asyncio
import requests
import re
import json
import random
import argparse
from pathlib import Path
from datetime import datetime
from urllib.parse import urlparse
from playwright.async_api import async_playwright
import time

# Configuraci√≥n de usuarios
CONFIG_FILE = "x_usernames.json"

def load_user_config():
    """Cargar configuraci√≥n de usuarios desde x_usernames.json"""
    if not os.path.exists(CONFIG_FILE):
        return {}
    
    try:
        with open(CONFIG_FILE, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception as e:
        print(f"‚ö†Ô∏è  Error al cargar configuraci√≥n: {e}")
        return {}

def save_user_config(config):
    """Guardar configuraci√≥n de usuarios en x_usernames.json"""
    try:
        with open(CONFIG_FILE, 'w', encoding='utf-8') as f:
            json.dump(config, f, indent=2, ensure_ascii=False)
        print(f"‚úÖ Configuraci√≥n guardada en {CONFIG_FILE}")
    except Exception as e:
        print(f"‚ö†Ô∏è  Error al guardar configuraci√≥n: {e}")

def get_user_by_name(name):
    """Obtener informaci√≥n de usuario por nombre amigable"""
    config = load_user_config()
    for user_data in config.values():
        if user_data.get('friendlyname') == name:
            return user_data
    return None

def add_new_user(name):
    """A√±adir un nuevo usuario a la configuraci√≥n"""
    config = load_user_config()
    
    print(f"üîß Configurando nuevo usuario: {name}")
    username = input("üìù Ingresa el username de X (sin @): ").strip()
    if username.startswith('@'):
        username = username[1:]
    
    # Validar que no est√© vac√≠o
    if not username:
        print("‚ùå El username no puede estar vac√≠o")
        return None
    
    # Verificar si el username ya existe
    if username in config:
        print(f"‚ö†Ô∏è  El username '{username}' ya existe en la configuraci√≥n")
        existing_user = config[username]
        print(f"   Nombre amigable: {existing_user.get('friendlyname')}")
        print(f"   Directorio: {existing_user.get('directory_download')}")
        return existing_user
    
    directory = input("üìÅ Ingresa la ruta del directorio de descarga: ").strip()
    if not directory:
        # Usar directorio por defecto basado en el nombre
        home_dir = Path.home()
        directory = str(home_dir / "Downloads" / f"X_Media_{name}")
        print(f"üìÅ Usando directorio por defecto: {directory}")
    
    # Crear el directorio si no existe
    Path(directory).mkdir(parents=True, exist_ok=True)
    
    user_data = {
        "friendlyname": name,
        "username": username,
        "directory_download": directory
    }
    
    config[username] = user_data
    save_user_config(config)
    
    return user_data

def list_configured_users():
    """Listar todos los usuarios configurados"""
    config = load_user_config()
    if not config:
        print("üìù No hay usuarios configurados a√∫n")
        return
    
    print("üë• Usuarios configurados:")
    print("=" * 50)
    for username, user_data in config.items():
        print(f"  ‚Ä¢ Nombre: {user_data.get('friendlyname')}")
        print(f"    Username: @{username}")
        print(f"    Directorio: {user_data.get('directory_download')}")
        print()

class EdgeXDownloader:
    def __init__(self, download_dir=None):
        """Inicializa el descargador para Microsoft Edge"""
        if download_dir is None:
            home_dir = Path.home()
            self.download_dir = home_dir / "Downloads" / "X_Media_Edge"
        else:
            self.download_dir = Path(download_dir)
        
        self.download_dir.mkdir(parents=True, exist_ok=True)
        
        # Configurar sesi√≥n HTTP
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8',
            'Accept-Language': 'es-ES,es;q=0.9,en;q=0.8',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1'
        })
        
        # Control de URLs para precisi√≥n mejorada
        self.processed_status_ids = set()

    def print_info(self):
        """Imprimir informaci√≥n de configuraci√≥n"""
        print(f"üìÅ Directorio de descarga: {self.download_dir}")
        print("üéØ Objetivo: Descargar im√°genes de la secci√≥n Media de X")
        print("‚ö†Ô∏è  NOTA: Los videos se detectan pero NO se descargan")
        print("üìπ Para videos usa: x_video_url_extractor.py")
        print()

    async def download_image(self, url, filename):
        """Descargar una imagen individual"""
        try:
            file_path = self.download_dir / filename
            
            response = self.session.get(url, timeout=30)
            response.raise_for_status()
            
            with open(file_path, 'wb') as f:
                f.write(response.content)
            
            return len(response.content)
        except Exception as e:
            print(f"‚ö†Ô∏è  Error descargando {filename}: {e}")
            return 0

    def clean_filename(self, url):
        """Crear nombre de archivo limpio desde URL"""
        try:
            parsed = urlparse(url)
            filename = os.path.basename(parsed.path)
            
            if not filename or '.' not in filename:
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S_%f")[:-3]
                filename = f"image_{timestamp}.jpg"
            
            # Limpiar caracteres problem√°ticos
            filename = re.sub(r'[<>:"/\\|?*]', '_', filename)
            
            return filename
        except Exception:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S_%f")[:-3]
            return f"image_{timestamp}.jpg"

    def is_video_url(self, url):
        """Determinar si una URL es de video usando criterios m√°s precisos"""
        # M√©todo 1: Buscar patrones espec√≠ficos de video en la URL
        video_patterns = [
            r'/video/1/',
            r'\.mp4',
            r'\.m4v',
            r'\.webm',
            r'ext_tw_video',
            r'video\.twimg\.com',
            r'/amplify_video/',
            r'/tweet_video/',
            r'format=mp4'
        ]
        
        for pattern in video_patterns:
            if re.search(pattern, url, re.IGNORECASE):
                return True
        
        # M√©todo 2: Si contiene /photo/1/ es definitivamente imagen
        if '/photo/1/' in url:
            return False
        
        # M√©todo 3: Extensiones de imagen conocidas
        image_extensions = ['.jpg', '.jpeg', '.png', '.gif', '.webp']
        url_lower = url.lower()
        if any(ext in url_lower for ext in image_extensions):
            return False
        
        return False

    def extract_status_id_from_url(self, url):
        """Extraer el ID del status/tweet desde la URL de media"""
        try:
            # Buscar patrones como /status/1234567890123456789/
            match = re.search(r'/status/(\d+)', url)
            if match:
                return match.group(1)
            
            # Tambi√©n buscar en par√°metros de query
            if 'status' in url:
                match = re.search(r'status[=/](\d+)', url)
                if match:
                    return match.group(1)
            
            return None
        except Exception:
            return None

    async def extract_media_urls_from_page(self, page):
        """Extraer URLs de medios con clasificaci√≥n mejorada"""
        print("üîç Extrayendo URLs de medios...")
        
        # Esperar a que la p√°gina cargue completamente
        try:
            await page.wait_for_selector('article[data-testid="tweet"]', timeout=10000)
        except Exception:
            print("‚ö†Ô∏è  No se encontraron tweets, continuando...")
        
        # Recopilar todas las URLs de im√°genes y videos
        all_urls = []
        
        # M√©todo 1: Interceptar requests de red
        network_urls = []
        
        def handle_response(response):
            url = response.url
            if any(domain in url for domain in ['pbs.twimg.com', 'video.twimg.com']):
                if url not in network_urls:
                    network_urls.append(url)
        
        page.on('response', handle_response)
        
        # Scroll para cargar m√°s contenido
        print("üìú Haciendo scroll para cargar contenido...")
        for _ in range(5):
            await page.evaluate("window.scrollTo(0, document.body.scrollHeight)")
            await asyncio.sleep(2)
        
        # M√©todo 2: Extraer desde elementos DOM
        dom_urls = await page.evaluate("""
            () => {
                const urls = [];
                
                // Buscar im√°genes en tweets
                const images = document.querySelectorAll('img[src*="pbs.twimg.com"]');
                images.forEach(img => {
                    if (img.src && !urls.includes(img.src)) {
                        urls.push(img.src);
                    }
                });
                
                // Buscar videos
                const videos = document.querySelectorAll('video[src], video source[src]');
                videos.forEach(video => {
                    const src = video.src || video.getAttribute('src');
                    if (src && !urls.includes(src)) {
                        urls.push(src);
                    }
                });
                
                // Buscar en atributos de datos
                const mediaContainers = document.querySelectorAll('[data-testid*="media"], [role="img"]');
                mediaContainers.forEach(container => {
                    const bgImage = window.getComputedStyle(container).backgroundImage;
                    if (bgImage && bgImage !== 'none') {
                        const match = bgImage.match(/url\\(["']?([^"']+)["']?\\)/);
                        if (match && match[1] && !urls.includes(match[1])) {
                            urls.push(match[1]);
                        }
                    }
                });
                
                return urls;
            }
        """)
        
        # Combinar URLs de ambos m√©todos
        all_urls = list(set(network_urls + dom_urls))
        
        # Filtrar y limpiar URLs
        filtered_urls = []
        for url in all_urls:
            # Filtrar URLs v√°lidas
            if (('pbs.twimg.com' in url or 'video.twimg.com' in url) and 
                'profile_images' not in url and 
                'profile_banners' not in url):
                
                # Limpiar par√°metros innecesarios pero mantener format y name
                clean_url = re.sub(r'&?[a-zA-Z0-9_]+=(?:large|medium|small|thumb)', '', url)
                clean_url = re.sub(r'\?.*?(?=&name=|&format=|$)', '?', clean_url)
                clean_url = re.sub(r'\?&', '?', clean_url)
                clean_url = re.sub(r'\?$', '', clean_url)
                
                # Asegurar calidad m√°xima para im√°genes
                if 'pbs.twimg.com' in clean_url and not self.is_video_url(clean_url):
                    if '?' in clean_url:
                        clean_url += '&name=large'
                    else:
                        clean_url += '?name=large'
                
                filtered_urls.append(clean_url)
        
        # Eliminar duplicados manteniendo orden
        unique_urls = []
        seen = set()
        for url in filtered_urls:
            if url not in seen:
                unique_urls.append(url)
                seen.add(url)
        
        # Clasificar URLs
        images = []
        videos = []
        
        for url in unique_urls:
            if self.is_video_url(url):
                videos.append(url)
            else:
                images.append(url)
        
        print(f"üìä URLs encontradas: {len(unique_urls)} total")
        print(f"   üì∑ Im√°genes: {len(images)}")
        print(f"   üé¨ Videos: {len(videos)}")
        
        return {
            'images': images,
            'videos': videos,
            'total': unique_urls
        }

    async def download_images_batch(self, urls, max_images=48):
        """Descargar im√°genes en lote con l√≠mite"""
        if not urls:
            print("‚ùå No hay im√°genes para descargar")
            return
        
        # Limitar n√∫mero de im√°genes
        download_urls = urls[:max_images]
        print(f"üì• Iniciando descarga de {len(download_urls)} im√°genes...")
        
        downloaded = 0
        skipped = 0
        
        for i, url in enumerate(download_urls, 1):
            try:
                filename = self.clean_filename(url)
                file_path = self.download_dir / filename
                
                # Verificar si ya existe
                if file_path.exists():
                    file_size = file_path.stat().st_size / (1024 * 1024)
                    print(f"‚¨áÔ∏è  [{i}/{len(download_urls)}] ‚è≠Ô∏è  {filename} ya existe ({file_size:.2f} MB)")
                    skipped += 1
                    continue
                
                print(f"‚¨áÔ∏è  [{i}/{len(download_urls)}] {filename}...")
                
                response = self.session.get(url, timeout=30)
                response.raise_for_status()
                
                with open(file_path, 'wb') as f:
                    f.write(response.content)
                
                size_mb = len(response.content) / (1024 * 1024)
                print(f"   ‚úÖ {filename} ({size_mb:.2f} MB)")
                downloaded += 1
                
                # Delay org√°nico entre descargas para ser respetuoso
                if i < len(download_urls):  # No esperar despu√©s del √∫ltimo archivo
                    await asyncio.sleep(random.uniform(0.3, 0.8))  # 300-800ms entre descargas
                
            except Exception as e:
                print(f"   ‚ùå Error: {e}")
                continue
        
        print(f"üìä Resumen de descarga:")
        print(f"   ‚úÖ Descargadas: {downloaded}")
        print(f"   ‚è≠Ô∏è  Saltadas (ya exist√≠an): {skipped}")
        print(f"   ‚ùå Errores: {len(download_urls) - downloaded - skipped}")

    async def save_session_data(self, media_data, profile_url, use_automation_profile):
        """Guardar datos de la sesi√≥n en JSON"""
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            session_dir = self.download_dir / f"session_{timestamp}"
            session_dir.mkdir(exist_ok=True)
            
            # Preparar datos del log
            log_data = {
                "session_info": {
                    "timestamp": timestamp,
                    "profile_url": profile_url,
                    "automation_profile": use_automation_profile,
                    "download_directory": str(self.download_dir)
                },
                "statistics": {
                    "total_urls": len(media_data['total']),
                    "images_found": len(media_data['images']),
                    "videos_found": len(media_data['videos']),
                    "images_downloaded": min(len(media_data['images']), 48)
                },
                "urls_classified": {
                    "images": media_data['images'][:48],  # Solo las primeras 48
                    "videos": media_data['videos'],
                    "all_urls": media_data['total']
                }
            }
            
            # Guardar log completo
            log_file = session_dir / "session_log.json"
            with open(log_file, 'w', encoding='utf-8') as f:
                json.dump(log_data, f, indent=2, ensure_ascii=False)
            
            print(f"üìã Log guardado: {log_file}")
            
        except Exception as e:
            print(f"‚ö†Ô∏è  No se pudo crear el log: {e}")

    async def download_with_edge(self, profile_url, use_automation_profile=True):
        """Ejecutar el proceso de descarga con Microsoft Edge"""
        self.print_info()
        
        async with async_playwright() as p:
            print("üöÄ Iniciando Microsoft Edge...")
            
            # Configurar contexto del navegador
            context_options = {
                "viewport": {"width": 1280, "height": 720},
                "user_agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36"
            }
            
            if use_automation_profile:
                # Usar perfil de automatizaci√≥n
                automation_dir = Path.home() / "Library" / "Application Support" / "Microsoft Edge" / "EdgeAutomation"
                automation_dir.mkdir(parents=True, exist_ok=True)
                context_options["user_data_dir"] = str(automation_dir)
                print("‚úÖ Usando perfil de automatizaci√≥n")
            else:
                print("‚úÖ Usando Edge temporal (sin datos persistentes)")
            
            browser = await p.chromium.launch_persistent_context(
                executable_path="/Applications/Microsoft Edge.app/Contents/MacOS/Microsoft Edge",
                headless=False,
                **context_options
            )
            
            try:
                page = browser.pages[0] if browser.pages else await browser.new_page()
                
                print(f"üåê Navegando a: {profile_url}")
                await page.goto(profile_url, wait_until="networkidle", timeout=30000)
                
                # Verificar si necesita login
                await asyncio.sleep(3)
                current_url = page.url
                
                if "login" in current_url or "i/flow/login" in current_url:
                    print("üîê Se requiere login. Por favor, inicia sesi√≥n manualmente...")
                    print("‚è≥ Esperando a que inicies sesi√≥n...")
                    
                    # Esperar hasta que salga de la p√°gina de login
                    while "login" in page.url or "i/flow/login" in page.url:
                        await asyncio.sleep(2)
                        print("‚è≥ A√∫n en p√°gina de login...")
                    
                    print("‚úÖ Login detectado, continuando...")
                    await page.goto(profile_url, wait_until="networkidle", timeout=30000)
                
                # Extraer URLs de medios
                media_data = await self.extract_media_urls_from_page(page)
                
                # Guardar datos de sesi√≥n
                await self.save_session_data(media_data, profile_url, use_automation_profile)
                
                # Descargar solo im√°genes (m√°ximo 48)
                if media_data['images']:
                    await self.download_images_batch(media_data['images'], max_images=48)
                else:
                    print("‚ùå No se encontraron im√°genes para descargar")
                
                if media_data['videos']:
                    print(f"üìπ Se detectaron {len(media_data['videos'])} videos (no descargados)")
                    print("üí° Para descargar videos usa: x_video_url_extractor.py")
                
            except Exception as e:
                print(f"‚ùå Error durante el proceso: {e}")
                import traceback
                traceback.print_exc()
            
            finally:
                print("üîö Cerrando navegador...")
                await browser.close()

async def main():
    """Funci√≥n principal"""
    # Configurar parser de argumentos
    parser = argparse.ArgumentParser(
        description='X Media Downloader - Optimizado para Microsoft Edge',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Ejemplos de uso:
  python3 edge_x_downloader_clean.py --name usuario1
  python3 edge_x_downloader_clean.py --name usuario1 --auto
  python3 edge_x_downloader_clean.py --list-users
  python3 edge_x_downloader_clean.py --username milewskaja_nat
        """
    )
    
    parser.add_argument('--name', '-n', 
                       help='Nombre amigable del usuario configurado')
    parser.add_argument('--username', '-u', 
                       help='Username de X directamente (sin @)')
    parser.add_argument('--directory', '-d', 
                       help='Directorio de descarga personalizado')
    parser.add_argument('--auto', '-a', action='store_true',
                       help='Usar perfil de automatizaci√≥n')
    parser.add_argument('--temporal', '-t', action='store_true',
                       help='Usar Edge temporal')
    parser.add_argument('--select', '-s', action='store_true',
                       help='Mostrar opciones para seleccionar modo')
    parser.add_argument('--list-users', action='store_true',
                       help='Listar usuarios configurados')
    
    args = parser.parse_args()
    
    # Listar usuarios y salir si se solicita
    if args.list_users:
        list_configured_users()
        return
    
    # Determinar configuraci√≥n de usuario
    user_data = None
    profile_url = None
    download_dir = None
    
    if args.name:
        # Buscar usuario por nombre amigable
        user_data = get_user_by_name(args.name)
        if not user_data:
            print(f"‚ùå Usuario '{args.name}' no encontrado en configuraci√≥n")
            user_data = add_new_user(args.name)
            if not user_data:
                print("‚ùå No se pudo configurar el usuario")
                return
        
        profile_url = f"https://x.com/{user_data['username']}/media"
        download_dir = user_data['directory_download']
        print(f"‚úÖ Usuario seleccionado: {user_data['friendlyname']} (@{user_data['username']})")
        
    elif args.username:
        # Usar username directamente
        username = args.username
        if username.startswith('@'):
            username = username[1:]
        
        profile_url = f"https://x.com/{username}/media"
        
        # Buscar en configuraci√≥n por si existe
        config = load_user_config()
        if username in config:
            user_data = config[username]
            download_dir = user_data['directory_download']
            print(f"‚úÖ Usuario encontrado en configuraci√≥n: {user_data['friendlyname']} (@{username})")
        else:
            # Usar directorio por defecto o especificado
            if args.directory:
                download_dir = args.directory
            else:
                home_dir = Path.home()
                download_dir = str(home_dir / "Downloads" / f"X_Media_{username}")
            print(f"üìù Usando username: @{username} (no est√° en configuraci√≥n)")
    
    else:
        # Modo por defecto (compatibilidad hacia atr√°s)
        profile_url = "https://x.com/milewskaja_nat/media"
        print("‚ö†Ô∏è  Usando configuraci√≥n por defecto. Para usar usuarios configurados:")
        print("   python3 edge_x_downloader_clean.py --name <usuario>")
        print("   python3 edge_x_downloader_clean.py --list-users")
        print()
    
    # Usar directorio personalizado si se especifica
    if args.directory:
        download_dir = args.directory
    
    # Determinar modo de navegador
    use_automation_profile = True  # Por defecto
    show_options = False
    
    if args.temporal:
        use_automation_profile = False
        show_options = True
    elif args.auto:
        use_automation_profile = True
        show_options = True
    elif args.select:
        show_options = True
        # Preguntar al usuario qu√© perfil usar
        print("üé¨ X Media Downloader - Seleccionar modo")
        print("=" * 50)
        print("1. Perfil de automatizaci√≥n (recomendado)")
        print("   ‚úÖ No interfiere con tu Edge principal")
        print("   ‚úÖ Mantiene sesi√≥n de X guardada")
        print("   ‚úÖ No requiere login cada vez")
        print()
        print("2. Edge temporal")
        print("   ‚ö†Ô∏è  Requiere login manual cada vez")
        print("   ‚úÖ No interfiere con datos existentes")
        print()
        
        choice = input("Selecciona modo (1/2): ").strip()
        if choice == "2":
            use_automation_profile = False
        else:
            use_automation_profile = True
    
    print("üé¨ X Media Downloader - Optimizado para Microsoft Edge")
    print("=" * 60)
    print(f"üéØ Perfil objetivo: {profile_url}")
    print("üì∑ Tipo de contenido: Solo im√°genes")
    print("üí° Para videos usa: python3 x_video_url_extractor.py")
    print()
    
    if show_options:
        if use_automation_profile:
            print("‚úÖ Usando perfil de automatizaci√≥n")
            print("   üîß Ventajas:")
            print("      ‚úÖ No interfiere con tu Edge principal")
            print("      ‚úÖ Mantiene sesi√≥n de X guardada")
            print("      ‚úÖ No requiere login cada vez")
        else:
            print("‚úÖ Usando Edge temporal")
            print("   üîß Caracter√≠sticas:")
            print("      ‚ö†Ô∏è  Requiere login manual cada vez")
            print("      ‚úÖ No interfiere con datos existentes")
        
        print()
        print("üí° Para cambiar modo en el futuro, usa: --auto, --temporal o --select")
        print()
        
        response = input("üöÄ ¬øContinuar? (s/n): ").lower().strip()
        if response not in ['s', 'si', 's√≠', 'y', 'yes']:
            print("‚ùå Cancelado por el usuario")
            return
    else:
        # Modo directo: mostrar solo informaci√≥n b√°sica y continuar
        print("‚úÖ Iniciando con perfil de automatizaci√≥n")
        print("üí° Usa --help para ver todas las opciones disponibles")
    
    print()
    downloader = EdgeXDownloader(download_dir)
    await downloader.download_with_edge(profile_url, use_automation_profile)
    
    print()
    print("üèÅ ¬°Proceso completado!")
    print("üìä Revisa el JSON generado para ver la clasificaci√≥n completa")
    print("üì∑ Se descargaron solo las primeras 48 im√°genes")
    print("üé¨ Para videos usa: python3 x_video_url_extractor.py o revisa el JSON")

if __name__ == "__main__":
    asyncio.run(main())
