#!/usr/bin/env python3
"""
Script optimizado para Microsoft Edge con descarga de im√°genes de X
Autor: Asistente AI
Fecha: 11 de junio de 2025

Este script est√° espec√≠ficamente dise√±ado para usar Microsoft Edge
donde ya tienes sesi√≥n iniciada en X, y maneja autom√°ticamente
la verificaci√≥n de login y navegaci√≥n.

IMPORTANTE: Este script descarga solo IM√ÅGENES de la secci√≥n Media.
Los videos requieren procesamiento interno de X y no pueden descargarse directamente.
"""

import os
import asyncio
import requests
import re
import json
import random
from pathlib import Path
from datetime import datetime
from urllib.parse import urlparse
from playwright.async_api import async_playwright
import time

class EdgeXDownloader:
    def __init__(self, download_dir=None):
        """Inicializa el descargador para Microsoft Edge"""
        if download_dir is None:
            home_dir = Path.home()
            self.download_dir = home_dir / "Downloads" / "X_Media_Edge"
        else:
            self.download_dir = Path(download_dir)
        
        self.download_dir.mkdir(parents=True, exist_ok=True)
        
        # Configurar sesi√≥n HTTP
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36 Edg/120.0.0.0'
        })
        
        print(f"üìÅ Directorio de descarga: {self.download_dir}")
    
    async def _organic_delay(self, min_ms=1000, max_ms=2000):
        """Espera org√°nica aleatoria para ser respetuoso con el servidor"""
        delay = random.randint(min_ms, max_ms)
        await asyncio.sleep(delay / 1000)  # Convertir a segundos
    
    async def download_with_edge(self, profile_url, use_automation_profile=True):
        """
        Descarga medios usando Microsoft Edge con sesi√≥n existente
        """
        print(f"üöÄ Iniciando con Microsoft Edge: {profile_url}")
        
        async with async_playwright() as p:
            # Configurar Microsoft Edge
            edge_path = "/Applications/Microsoft Edge.app/Contents/MacOS/Microsoft Edge"
            
            print("üåê Configurando Microsoft Edge...")
            
            try:
                browser = None  # Inicializar variable
                
                if use_automation_profile:
                    # OPCI√ìN SEGURA: Usar perfil separado para automatizaci√≥n
                    automation_dir = Path.home() / "Library" / "Application Support" / "Microsoft Edge Automation"
                    automation_dir.mkdir(exist_ok=True)
                    
                    print(f"   üìÇ Usando perfil de automatizaci√≥n: {automation_dir}")
                    print("   ‚ö†Ô∏è  NOTA: Necesitar√°s hacer login manualmente en este perfil")
                    
                    context = await p.chromium.launch_persistent_context(
                        user_data_dir=str(automation_dir),
                        headless=False,
                        executable_path=edge_path,
                        args=[
                            '--no-first-run',
                            '--no-default-browser-check',
                            '--disable-default-apps',
                            '--window-size=1920,1080'
                        ]
                    )
                else:
                    # OPCI√ìN ALTERNATIVA: Lanzar Edge normal (sin datos persistentes)
                    print("   üìÇ Usando Edge temporal (sin persistencia)")
                    browser = await p.chromium.launch(
                        headless=False,
                        executable_path=edge_path,
                        args=[
                            '--no-first-run',
                            '--no-default-browser-check',
                            '--window-size=1920,1080'
                        ]
                    )
                    context = await browser.new_context()
                
                page = await context.new_page()
                
                # Navegar a la p√°gina
                await self._navigate_and_verify(page, profile_url)
                
                # Extraer y descargar medios
                await self._extract_and_download(page, profile_url)
                
            except Exception as e:
                print(f"‚ùå Error: {e}")
                print("üí° Sugerencias:")
                print("   ‚Ä¢ Aseg√∫rate de que Microsoft Edge est√© instalado")
                print("   ‚Ä¢ Cierra Edge completamente antes de ejecutar el script")
                print("   ‚Ä¢ Verifica que tengas sesi√≥n activa en X si usas perfil de automatizaci√≥n")
            
            finally:
                try:
                    if use_automation_profile:
                        await context.close()
                    else:
                        await context.close()
                        if 'browser' in locals():
                            await browser.close()
                except:
                    pass
    
    async def _navigate_and_verify(self, page, profile_url):
        """Navega y verifica el estado de la p√°gina"""
        print(f"üì± Navegando a: {profile_url}")
        
        # Navegar a la p√°gina
        await page.goto(profile_url, wait_until='domcontentloaded', timeout=30000)
        await self._organic_delay(2000, 4000)  # Espera inicial m√°s larga
        
        # Verificar t√≠tulo de la p√°gina
        title = await page.title()
        print(f"üìÑ T√≠tulo de p√°gina: {title}")
        
        # Verificar si necesitamos login
        if await self._check_login_needed(page):
            await self._handle_login_process(page)
        
        # Verificar y navegar a Media
        await self._ensure_media_section(page, profile_url)
    
    async def _check_login_needed(self, page):
        """Verifica si necesitamos hacer login"""
        login_indicators = [
            'text=Iniciar sesi√≥n',
            'text=Log in',
            'text=Reg√≠strate', 
            'text=Sign up',
            'text=No te pierdas lo que est√° pasando'
        ]
        
        for indicator in login_indicators:
            try:
                if await page.locator(indicator).count() > 0:
                    return True
            except:
                continue
        
        return False
    
    async def _handle_login_process(self, page):
        """Maneja el proceso de login"""
        print("üîê SE REQUIERE LOGIN")
        print("=" * 50)
        print("üìã INSTRUCCIONES:")
        print("   1. En la ventana del navegador que se acaba de abrir:")
        print("   2. Haz clic en 'Iniciar sesi√≥n' o 'Log in'")
        print("   3. Ingresa tu usuario/email y contrase√±a")
        print("   4. Completa verificaci√≥n 2FA si es necesario")
        print("   5. Espera a llegar al perfil de usuario")
        print("=" * 50)
        
        # Esperar respuesta del usuario
        response = input("‚úÖ ¬øHas completado el login? (s/n): ").lower().strip()
        
        if response in ['s', 'si', 's√≠', 'y', 'yes']:
            print("‚úÖ Continuando...")
            await self._organic_delay(1500, 3000)
        else:
            print("‚è≥ Esperando m√°s tiempo para login...")
            await self._organic_delay(8000, 12000)
    
    async def _ensure_media_section(self, page, profile_url):
        """Asegura que estemos en la secci√≥n de medios"""
        print("üì± Verificando secci√≥n de medios...")
        
        # Buscar tabs del perfil
        tabs_info = await page.evaluate("""
            () => {
                const tabs = [];
                
                // Buscar tabs por diferentes selectores
                const tabElements = document.querySelectorAll('a[role="tab"], [data-testid*="Tab"]');
                
                tabElements.forEach(el => {
                    const text = el.textContent.trim();
                    if (text && (
                        text.includes('Posts') || 
                        text.includes('Replies') || 
                        text.includes('Media') ||
                        text.includes('Publicaciones') ||
                        text.includes('Respuestas') ||
                        text.includes('Multimedia')
                    )) {
                        tabs.push({
                            text: text,
                            href: el.href || '',
                            selected: el.getAttribute('aria-selected') === 'true' || 
                                     el.classList.contains('selected') ||
                                     el.getAttribute('data-selected') === 'true'
                        });
                    }
                });
                
                return tabs;
            }
        """)
        
        print(f"üîç Tabs encontrados: {len(tabs_info)}")
        for tab in tabs_info:
            status = "‚úÖ SELECCIONADO" if tab.get('selected') else ""
            print(f"   üì± {tab.get('text')} {status}")
        
        # Buscar tab de Media/Multimedia
        media_tab_clicked = False
        
        # Intentar hacer clic en el tab de Media usando diferentes m√©todos
        try:
            # M√©todo 1: Buscar tabs que contengan "Media"
            tabs = await page.locator('a[role="tab"]').all()
            for tab in tabs:
                text = await tab.text_content()
                if text and "Media" in text:
                    print(f"üì± Haciendo clic en tab Media...")
                    await tab.click()
                    await self._organic_delay(1500, 2500)
                    media_tab_clicked = True
                    break
                elif text and "Multimedia" in text:
                    print(f"üì± Haciendo clic en tab Multimedia...")
                    await tab.click()
                    await self._organic_delay(1500, 2500)
                    media_tab_clicked = True
                    break
        except Exception as e:
            print(f"‚ö†Ô∏è  Error con locators: {e}")
        
        # M√©todo 3: Usar evaluate para hacer clic
        if not media_tab_clicked:
            try:
                clicked = await page.evaluate("""
                    () => {
                        const tabs = document.querySelectorAll('a[role="tab"]');
                        for (let tab of tabs) {
                            const text = tab.textContent.trim();
                            if (text.includes('Media') || text.includes('Multimedia')) {
                                tab.click();
                                return true;
                            }
                        }
                        return false;
                    }
                """)
                
                if clicked:
                    print(f"üì± Tab Media encontrado y clickeado con JavaScript")
                    await self._organic_delay(1500, 2500)
                    media_tab_clicked = True
            except Exception as e:
                print(f"‚ö†Ô∏è  Error con JavaScript: {e}")
        
        if not media_tab_clicked:
            print("‚ö†Ô∏è  No se encontr√≥ tab Media, navegando directamente...")
            # Construir URL de medios
            if '/media' not in page.url:
                username = profile_url.split('/')[-2] if profile_url.endswith('/media') else profile_url.split('/')[-1]
                media_url = f"https://x.com/{username}/media"
                await page.goto(media_url)
                await self._organic_delay(2000, 3000)
        
        # Verificar URL final
        final_url = page.url
        print(f"‚úÖ URL final: {final_url}")
        
        if '/media' in final_url:
            print("‚úÖ En la secci√≥n de medios correcta")
        else:
            print("‚ö†Ô∏è  Puede que no estemos en la secci√≥n de medios")
    
    async def _extract_and_download(self, page, profile_url):
        """Extrae y descarga los medios con estrategia de scroll y procesamiento en tiempo real"""
        print("üìú Iniciando estrategia de scroll y procesamiento en tiempo real...")
        
        username = self._extract_username(profile_url)
        all_processed_urls = set()  # Para evitar duplicados
        
        # Hacer scroll y procesar por chunks
        await self._scroll_and_process_in_real_time(page, username, all_processed_urls)
        
        print(f"‚úÖ Procesamiento completado. Total URLs √∫nicas procesadas: {len(all_processed_urls)}")

    async def _scroll_and_process_in_real_time(self, page, username, all_processed_urls):
        """Hace scroll y procesa URLs en tiempo real cuando el conteo baja (solo im√°genes)"""
        previous_count = 0
        max_count_seen = 0
        
        for i in range(50):  # M√°ximo 50 scrolls
            # Contar elementos actuales (solo fotos, no videos)
            current_count = await page.evaluate("""
                () => document.querySelectorAll('a[href*="/photo/"]').length
            """)
            
            print(f"   Scroll {i+1}/50 - Im√°genes: {current_count}")
            
            # Actualizar el m√°ximo visto
            if current_count > max_count_seen:
                max_count_seen = current_count
            
            # Si el conteo baja significativamente del m√°ximo, procesar antes de perder URLs
            if max_count_seen > 0 and current_count < max_count_seen * 0.8:
                print(f"   üéØ Conteo baj√≥ de {max_count_seen} a {current_count}, procesando antes de perder URLs...")
                await self._process_current_visible_urls(page, username, all_processed_urls)
                max_count_seen = current_count  # Resetear el m√°ximo
            
            # Si no hay cambios por varios scrolls, hacer procesamiento final
            if current_count == previous_count:
                stable_count = getattr(self, '_stable_count', 0) + 1
                self._stable_count = stable_count
                
                if stable_count >= 3 and i > 5:
                    print(f"   ‚úÖ Conteo estable en {current_count}, procesamiento final...")
                    await self._process_current_visible_urls(page, username, all_processed_urls)
                    break
            else:
                self._stable_count = 0
            
            previous_count = current_count
            
            # Scroll org√°nico m√°s lento para permitir mejor carga
            await page.evaluate("window.scrollTo(0, document.body.scrollHeight)")
            await self._organic_delay(2500, 3500)  # Delay m√°s largo para mejor carga de contenido
        
        # Procesamiento final por si quedaron URLs
        print(f"   üèÅ Procesamiento final de im√°genes restantes...")
        await self._process_current_visible_urls(page, username, all_processed_urls)

    async def _process_current_visible_urls(self, page, username, all_processed_urls):
        """Procesa las URLs de im√°genes actualmente visibles en la p√°gina"""
        # Extraer URLs de im√°genes visibles (solo fotos, no videos)
        media_urls = await page.evaluate("""
            () => {
                const mediaUrls = new Set();
                const links = document.querySelectorAll('a[href*="/photo/"]');
                links.forEach(link => mediaUrls.add(link.href));
                return Array.from(mediaUrls);
            }
        """)
        
        # Filtrar solo URLs nuevas
        new_urls = [url for url in media_urls if url not in all_processed_urls]
        
        if new_urls:
            print(f"   üîó Procesando {len(new_urls)} im√°genes nuevas de {len(media_urls)} visibles...")
            
            # Obtener URLs directas
            direct_urls = await self._get_direct_media_urls_batch(page, new_urls)
            
            if direct_urls:
                # Descargar archivos
                await self._download_files(direct_urls, username)
            
            # Marcar URLs como procesadas
            all_processed_urls.update(new_urls)
        else:
            print(f"   ‚úÖ Todas las {len(media_urls)} im√°genes ya fueron procesadas")

    async def _get_direct_media_urls_batch(self, page, media_urls):
        """Versi√≥n optimizada para procesar lotes de URLs de im√°genes solamente"""
        print(f"üîó Extrayendo URLs directas de {len(media_urls)} im√°genes...")
        direct_urls = []
        processed = 0
        
        for i, url in enumerate(media_urls):
            try:
                print(f"   [{i+1}/{len(media_urls)}] Procesando: {url}")
                
                await page.goto(url, wait_until='domcontentloaded')
                await self._organic_delay(1200, 1800)  # Delay optimizado para mejor detecci√≥n
                
                # Extraer URLs de im√°genes solamente (no procesar videos)
                media_data = await page.evaluate("""
                    () => {
                        const urls = new Set();
                        let imageCount = 0;
                        let otherCount = 0;
                        
                        // Buscar im√°genes de media
                        const images = document.querySelectorAll('img[src*="pbs.twimg.com"]');
                        images.forEach(img => {
                            if (img.src && img.src.includes('pbs.twimg.com')) {
                                if (img.src.includes('pbs.twimg.com/media/')) {
                                    let url = img.src;
                                    if (url.includes('?')) {
                                        url = url.split('?')[0];
                                    }
                                    url = url + '?format=jpg&name=large';
                                    urls.add(url);
                                    imageCount++;
                                } else {
                                    otherCount++;
                                }
                            }
                        });
                        
                        // Buscar en todos los elementos con background-image
                        const allBgElements = document.querySelectorAll('*');
                        allBgElements.forEach(el => {
                            const bgImage = window.getComputedStyle(el).backgroundImage;
                            if (bgImage && bgImage.includes('pbs.twimg.com/media/')) {
                                const match = bgImage.match(/url\\("?([^"]*)"?\\)/);
                                if (match) {
                                    let url = match[1];
                                    if (url.includes('?')) {
                                        url = url.split('?')[0];
                                    }
                                    url = url + '?format=jpg&name=large';
                                    urls.add(url);
                                    imageCount++;
                                }
                            }
                        });
                        
                        return {urls: Array.from(urls), imageCount, otherCount};
                    }
                """)
                
                if len(media_data['urls']) > 0:
                    print(f"      ‚úÖ {media_data['imageCount']} im√°genes, {media_data['otherCount']} otras")
                    direct_urls.extend(media_data['urls'])
                    processed += 1
                else:
                    print(f"      ‚ö†Ô∏è  No se encontraron URLs de im√°genes ({media_data['otherCount']} otras URLs)")
                
            except Exception as e:
                print(f"      ‚ùå Error: {e}")
                continue
        
        # Filtrar solo im√°genes v√°lidas del directorio /media/
        filtered_urls = []
        for url in set(direct_urls):
            # Solo URLs de im√°genes de pbs.twimg.com/media/
            if ('/media/' in url and 'pbs.twimg.com' in url):
                # Validaci√≥n adicional: URLs no deben ser demasiado cortas o gen√©ricas
                if len(url) > 30 and not url.endswith('/') and 'placeholder' not in url.lower():
                    filtered_urls.append(url)
        
        print(f"‚úÖ Procesadas {processed}/{len(media_urls)} p√°ginas exitosamente")
        print(f"‚úÖ URLs de im√°genes filtradas: {len(filtered_urls)} (solo /media/)")
        return filtered_urls
    
    def _extract_media_filename(self, url):
        """Extrae el nombre de archivo del ID del media (solo im√°genes)"""
        try:
            # Solo para im√°genes del directorio /media/
            if '/media/' in url and 'pbs.twimg.com' in url:
                # Extraer la parte despu√©s de /media/
                media_part = url.split('/media/')[1]
                
                # Obtener el ID antes de los par√°metros
                media_id = media_part.split('?')[0]
                
                # Determinar extensi√≥n basada en el formato
                if 'format=jpg' in url or 'format=jpeg' in url:
                    extension = '.jpg'
                elif 'format=png' in url:
                    extension = '.png'
                elif 'format=webp' in url:
                    extension = '.webp'
                elif '.gif' in url:
                    extension = '.gif'
                else:
                    extension = '.jpg'  # Por defecto
                
                return f"{media_id}{extension}"
            
            return None
            
        except Exception as e:
            print(f"   ‚ö†Ô∏è  Error extrayendo nombre: {e}")
            return None

    async def _download_files(self, urls, username):
        """Descarga los archivos de im√°genes con nombres inteligentes y verificaci√≥n de existencia"""
        # Usar siempre el mismo directorio para el usuario (sin timestamp)
        session_dir = self.download_dir / username
        session_dir.mkdir(exist_ok=True)
        
        print(f"üíæ Descargando {len(urls)} im√°genes...")
        
        downloaded = 0
        skipped = 0
        failed = 0
        
        for i, url in enumerate(urls, 1):
            try:
                # Extraer nombre de archivo inteligente
                filename = self._extract_media_filename(url)
                if not filename:
                    print(f"‚¨áÔ∏è  [{i}/{len(urls)}] ‚ö†Ô∏è  No es URL de imagen v√°lida, omitiendo...")
                    skipped += 1
                    continue
                
                file_path = session_dir / filename
                
                # Verificar si el archivo ya existe
                if file_path.exists():
                    file_size = file_path.stat().st_size / (1024 * 1024)
                    print(f"‚¨áÔ∏è  [{i}/{len(urls)}] ‚è≠Ô∏è  {filename} ya existe ({file_size:.2f} MB)")
                    skipped += 1
                    continue
                
                print(f"‚¨áÔ∏è  [{i}/{len(urls)}] {filename}...")
                
                response = self.session.get(url, timeout=30)
                response.raise_for_status()
                
                with open(file_path, 'wb') as f:
                    f.write(response.content)
                
                size_mb = len(response.content) / (1024 * 1024)
                print(f"   ‚úÖ {filename} ({size_mb:.2f} MB)")
                downloaded += 1
                
                # Delay org√°nico entre descargas para ser respetuoso
                if i < len(urls):  # No esperar despu√©s del √∫ltimo archivo
                    await asyncio.sleep(random.uniform(0.3, 0.8))  # 300-800ms entre descargas
                
            except Exception as e:
                print(f"   ‚ùå Error: {e}")
                failed += 1
        
        print(f"üìä Descarga completada:")
        print(f"   ‚úÖ {downloaded} im√°genes descargadas")
        print(f"   ‚è≠Ô∏è  {skipped} omitidas (ya exist√≠an o no v√°lidas)")
        print(f"   ‚ùå {failed} fallidas")
        print(f"üìÇ Archivos en: {session_dir}")
        
        # Crear log con timestamp de la sesi√≥n actual
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        log_data = {
            'session_timestamp': timestamp,
            'username': username,
            'downloaded': downloaded,
            'skipped': skipped,
            'failed': failed,
            'total_urls': len(urls),
            'image_urls': [url for url in urls if '/media/' in url]
        }
        
        # Crear archivo de log con timestamp √∫nico
        log_filename = f'edge_download_log_{timestamp}.json'
        with open(session_dir / log_filename, 'w') as f:
            json.dump(log_data, f, indent=2)
    
    def _extract_username(self, url):
        """Extrae nombre de usuario de URL"""
        try:
            parts = url.split('/')
            for i, part in enumerate(parts):
                if part in ['x.com', 'twitter.com'] and i + 1 < len(parts):
                    return parts[i + 1]
            return 'unknown_user'
        except:
            return 'unknown_user'

async def main():
    """Funci√≥n principal"""
    import sys
    
    profile_url = "https://x.com/milewskaja_nat/media"
    
    # Determinar modo basado en argumentos de l√≠nea de comandos
    use_automation_profile = True  # Por defecto usar perfil automatizado
    show_options = False  # Solo mostrar opciones si se especifica
    
    if len(sys.argv) > 1:
        if sys.argv[1] == "--temporal" or sys.argv[1] == "-t":
            use_automation_profile = False
            show_options = True
        elif sys.argv[1] == "--auto" or sys.argv[1] == "-a":
            use_automation_profile = True
            show_options = True
        elif sys.argv[1] == "--select" or sys.argv[1] == "-s":
            show_options = True
            # Preguntar al usuario qu√© perfil usar
            print("üé¨ X Media Downloader - Seleccionar modo")
            print("=" * 50)
            print("1. Perfil de automatizaci√≥n (recomendado)")
            print("   ‚úÖ No interfiere con tu Edge principal")
            print("   ‚úÖ Mantiene sesi√≥n de X guardada")
            print("   ‚úÖ No requiere login cada vez")
            print()
            print("2. Edge temporal")
            print("   ‚ö†Ô∏è  Requiere login manual cada vez")
            print("   ‚úÖ No interfiere con datos existentes")
            print()
            
            choice = input("Selecciona modo (1/2): ").strip()
            if choice == "2":
                use_automation_profile = False
            else:
                use_automation_profile = True
        elif sys.argv[1] == "--help" or sys.argv[1] == "-h":
            print("üé¨ X Media Downloader - Uso:")
            print("  python3 edge_x_downloader.py              # Ejecutar directamente con perfil automatizado")
            print("  python3 edge_x_downloader.py --auto       # Usar perfil automatizado")
            print("  python3 edge_x_downloader.py --temporal   # Usar Edge temporal")
            print("  python3 edge_x_downloader.py --select     # Mostrar opciones para seleccionar")
            print("  python3 edge_x_downloader.py --help       # Mostrar ayuda")
            print()
            print("üí° NOTA: Este script descarga solo IM√ÅGENES de la secci√≥n Media.")
            print("   Los videos requieren procesamiento interno de X y no pueden descargarse directamente.")
            return
    
    print("üé¨ X Media Downloader - Optimizado para Microsoft Edge")
    print("=" * 60)
    print(f"üéØ Perfil objetivo: {profile_url}")
    print("üì∑ Tipo de contenido: Solo im√°genes (no videos)")
    print()
    
    if show_options:
        if use_automation_profile:
            print("‚úÖ Usando perfil de automatizaci√≥n")
            print("   üîß Ventajas:")
            print("      ‚úÖ No interfiere con tu Edge principal")
            print("      ‚úÖ Mantiene sesi√≥n de X guardada")
            print("      ‚úÖ No requiere login cada vez")
        else:
            print("‚úÖ Usando Edge temporal")
            print("   üîß Caracter√≠sticas:")
            print("      ‚ö†Ô∏è  Requiere login manual cada vez")
            print("      ‚úÖ No interfiere con datos existentes")
        
        print()
        print("üí° Para cambiar modo en el futuro, usa: --auto, --temporal o --select")
        print()
        
        response = input("üöÄ ¬øContinuar? (s/n): ").lower().strip()
        if response not in ['s', 'si', 's√≠', 'y', 'yes']:
            print("‚ùå Cancelado por el usuario")
            return
    else:
        # Modo directo: mostrar solo informaci√≥n b√°sica y continuar
        print("‚úÖ Iniciando con perfil de automatizaci√≥n")
        print("üí° Usa --help para ver todas las opciones disponibles")
    
    print()
    downloader = EdgeXDownloader()
    await downloader.download_with_edge(profile_url, use_automation_profile)
    
    print()
    print("üèÅ ¬°Proceso completado!")
    print("üì∑ Solo se procesaron im√°genes (los videos no son descargables directamente)")

if __name__ == "__main__":
    asyncio.run(main())
