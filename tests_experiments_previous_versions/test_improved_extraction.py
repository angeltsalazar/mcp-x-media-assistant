#!/usr/bin/env python3
"""
Test de la nueva implementaciÃ³n mejorada de edge_x_downloader_clean.py
Verifica que use la lÃ³gica de simple_video_extractor.py para extraer medios
"""

import asyncio
import sys
import os
from pathlib import Path

# AÃ±adir el directorio actual al path
sys.path.append('/Volumes/SSDWD2T/projects/asistente_computadora')

from edge_x_downloader_clean import EdgeXDownloader

async def test_improved_extraction():
    """Test de la extracciÃ³n mejorada sin descarga"""
    
    print("ğŸ§ª TESTING IMPROVED MEDIA EXTRACTION")
    print("=" * 60)
    print("Usando la lÃ³gica mejorada de simple_video_extractor.py")
    print("Sin descargar archivos, solo probando extracciÃ³n")
    print()
    
    # Crear downloader de prueba
    test_dir = "/tmp/edge_test"
    downloader = EdgeXDownloader(test_dir)
    
    # URL de prueba
    profile_url = "https://x.com/milewskaja_nat/media"
    
    print(f"ğŸ¯ URL objetivo: {profile_url}")
    print("ğŸš€ Iniciando test...")
    print()
    
    # Ejecutar solo la parte de extracciÃ³n
    try:
        from playwright.async_api import async_playwright
        
        async with async_playwright() as p:
            # Usar perfil de automatizaciÃ³n
            automation_dir = Path.home() / "Library" / "Application Support" / "Microsoft Edge" / "EdgeAutomation"
            automation_dir.mkdir(parents=True, exist_ok=True)
            
            context = await p.chromium.launch_persistent_context(
                user_data_dir=str(automation_dir),
                headless=False,
                executable_path="/Applications/Microsoft Edge.app/Contents/MacOS/Microsoft Edge",
                viewport={"width": 1280, "height": 720}
            )
            
            try:
                page = context.pages[0] if context.pages else await context.new_page()
                
                print("ğŸŒ Navegando al perfil...")
                await page.goto(profile_url, wait_until="load", timeout=30000)
                await asyncio.sleep(3)
                
                # Verificar login
                if "login" in page.url:
                    print("âš ï¸  Se requiere login. Esperando login manual...")
                    while "login" in page.url:
                        await asyncio.sleep(2)
                    print("âœ… Login detectado")
                    await page.goto(profile_url, wait_until="load", timeout=30000)
                    await asyncio.sleep(3)
                
                print("ğŸ” Extrayendo medios usando nueva lÃ³gica...")
                
                # Probar la nueva funciÃ³n de extracciÃ³n
                media_data = await downloader.extract_media_urls_from_page(page)
                
                print(f"\nğŸ“Š RESULTADOS:")
                print(f"   ğŸ“¹ Total URLs extraÃ­das: {len(getattr(downloader, 'all_status_urls', []))}")
                
                # Contar videos e imÃ¡genes
                all_status = getattr(downloader, 'all_status_urls', [])
                videos = [item for item in all_status if item.get('media_type') == 'video']
                images = [item for item in all_status if item.get('media_type') == 'image']
                
                print(f"   ğŸ¬ Videos detectados: {len(videos)}")
                print(f"   ğŸ“· ImÃ¡genes detectadas: {len(images)}")
                print(f"   ğŸ“· URLs directas de imÃ¡genes: {len(media_data.get('images', []))}")
                
                # Mostrar algunas URLs de video encontradas
                if videos:
                    print(f"\nğŸ¬ URLs de Videos (primeras 5):")
                    for i, video in enumerate(videos[:5], 1):
                        print(f"   {i}. {video['url']}")
                
                # Mostrar algunas URLs de imagen
                if media_data.get('images'):
                    print(f"\nğŸ“· URLs de ImÃ¡genes Directas (primeras 5):")
                    for i, img_url in enumerate(media_data['images'][:5], 1):
                        print(f"   {i}. {img_url}")
                
                # Generar JSON de prueba
                print(f"\nğŸ’¾ Generando JSON de prueba...")
                json_file = await downloader.save_media_json(profile_url, True)
                
                if json_file:
                    print(f"âœ… JSON generado: {json_file}")
                
                # Verificar si encontramos las URLs especÃ­ficas mencionadas en el documento
                target_ids = ["1930265846783377473", "1927003705959678028", "1915047384612241420"]
                found_targets = []
                
                for item in all_status:
                    if any(target_id in item['url'] for target_id in target_ids):
                        found_targets.append(item['url'])
                
                if found_targets:
                    print(f"\nğŸ¯ URLs especÃ­ficas encontradas:")
                    for url in found_targets:
                        print(f"   âœ… {url}")
                else:
                    print(f"\nğŸ” URLs especÃ­ficas del documento no encontradas en esta sesiÃ³n")
                
                print(f"\nâœ… TEST COMPLETADO EXITOSAMENTE")
                print(f"ğŸ“Š Resumen: {len(all_status)} medios, {len(videos)} videos, {len(images)} imÃ¡genes")
                
            finally:
                await context.close()
                
    except Exception as e:
        print(f"âŒ Error durante el test: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    asyncio.run(test_improved_extraction())
