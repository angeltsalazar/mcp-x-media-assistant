#!/usr/bin/env python3
"""
AutomatizaciÃ³n completa para descargar medios de X usando Playwright
Autor: Asistente AI
Fecha: 11 de junio de 2025

Este script utiliza Playwright para navegar a una pÃ¡gina de medios de X,
extraer todas las URLs de imÃ¡genes y videos, y descargarlos automÃ¡ticamente
al directorio Downloads del usuario.
"""

import os
import asyncio
import requests
import re
import json
from pathlib import Path
from datetime import datetime
from urllib.parse import urlparse, urljoin
from playwright.async_api import async_playwright
import time

class XMediaDownloaderAutomation:
    def __init__(self, download_dir=None):
        """Inicializa el descargador automÃ¡tico"""
        if download_dir is None:
            home_dir = Path.home()
            self.download_dir = home_dir / "Downloads" / "X_Media_Automation"
        else:
            self.download_dir = Path(download_dir)
        
        self.download_dir.mkdir(parents=True, exist_ok=True)
        
        # Configurar sesiÃ³n HTTP para descargas
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'image/webp,image/apng,image/*,*/*;q=0.8',
            'Accept-Language': 'en-US,en;q=0.9',
            'Accept-Encoding': 'gzip, deflate, br',
            'DNT': '1',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
        })
        
        print(f"ğŸ“ Directorio de descarga: {self.download_dir}")
    
    async def extract_and_download_media(self, profile_url):
        """
        FunciÃ³n principal que extrae y descarga medios
        """
        print(f"ğŸš€ Iniciando automatizaciÃ³n para: {profile_url}")
        
        async with async_playwright() as p:
            # Configurar navegador
            browser = await p.chromium.launch(
                headless=False,  # Cambiar a True para ejecutar sin ventana
                args=[
                    '--no-sandbox',
                    '--disable-dev-shm-usage',
                    '--disable-blink-features=AutomationControlled',
                    '--disable-extensions',
                ]
            )
            
            context = await browser.new_context(
                viewport={'width': 1920, 'height': 1080},
                user_agent='Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
            )
            
            page = await context.new_page()
            
            try:
                # Navegar a la pÃ¡gina de medios
                print(f"ğŸ“± Navegando a: {profile_url}")
                await page.goto(profile_url, wait_until='domcontentloaded', timeout=60000)
                await page.wait_for_timeout(3000)
                
                # Hacer clic en la pestaÃ±a Media si no estamos ya ahÃ­
                if '/media' not in profile_url:
                    try:
                        await page.click('text=Media')
                        await page.wait_for_timeout(2000)
                    except:
                        # Si hay un modal, cerrarlo
                        try:
                            await page.keyboard.press('Escape')
                            await page.wait_for_timeout(1000)
                            await page.click('text=Media')
                            await page.wait_for_timeout(2000)
                        except:
                            print("âš ï¸  No se pudo hacer clic en la pestaÃ±a Media")
                
                # Scroll para cargar mÃ¡s contenido
                print("ğŸ“œ Cargando contenido con scroll...")
                await self._scroll_to_load_content(page)
                
                # Extraer URLs de medios
                media_urls = await self._extract_media_urls_from_page(page)
                
                if media_urls:
                    print(f"ğŸ¯ Encontrados {len(media_urls)} archivos multimedia")
                    
                    # Descargar archivos
                    username = self._extract_username_from_url(profile_url)
                    await self._download_media_files(media_urls, username, profile_url)
                else:
                    print("âŒ No se encontraron archivos multimedia")
                
            except Exception as e:
                print(f"âŒ Error durante la automatizaciÃ³n: {e}")
            
            finally:
                await browser.close()
    
    async def _scroll_to_load_content(self, page, max_scrolls=20):
        """Hace scroll para cargar mÃ¡s contenido"""
        print("ğŸ“œ Haciendo scroll para cargar mÃ¡s contenido...")
        
        previous_count = 0
        no_change_count = 0
        
        for i in range(max_scrolls):
            # Contar elementos multimedia actuales
            current_count = await page.evaluate("""
                () => {
                    const mediaLinks = document.querySelectorAll('a[href*="/photo/"], a[href*="/video/"]');
                    return mediaLinks.length;
                }
            """)
            
            print(f"   Scroll {i+1}/{max_scrolls} - Elementos encontrados: {current_count}")
            
            # Si no hay cambios en 3 scrolls consecutivos, parar
            if current_count == previous_count:
                no_change_count += 1
                if no_change_count >= 3:
                    print("âœ… No hay mÃ¡s contenido que cargar")
                    break
            else:
                no_change_count = 0
            
            previous_count = current_count
            
            # Hacer scroll
            await page.evaluate("window.scrollTo(0, document.body.scrollHeight)")
            await page.wait_for_timeout(2000)
        
        print(f"âœ… Scroll completado. Total de elementos: {current_count}")
    
    async def _extract_media_urls_from_page(self, page):
        """Extrae todas las URLs de medios de la pÃ¡gina"""
        print("ğŸ” Extrayendo URLs de medios...")
        
        media_urls = await page.evaluate("""
            () => {
                const mediaUrls = new Set();
                
                // Buscar enlaces de fotos
                const photoLinks = document.querySelectorAll('a[href*="/photo/"]');
                photoLinks.forEach(link => {
                    mediaUrls.add(link.href);
                });
                
                // Buscar enlaces de videos
                const videoLinks = document.querySelectorAll('a[href*="/video/"]');
                videoLinks.forEach(link => {
                    mediaUrls.add(link.href);
                });
                
                return Array.from(mediaUrls);
            }
        """)
        
        print(f"ğŸ” URLs de medios extraÃ­das: {len(media_urls)}")
        return media_urls
    
    async def _get_actual_media_urls(self, media_page_urls):
        """
        Convierte URLs de pÃ¡ginas de medios a URLs directas de archivos
        """
        print("ğŸ”— Convirtiendo URLs de pÃ¡ginas a URLs directas...")
        direct_urls = []
        
        async with async_playwright() as p:
            browser = await p.chromium.launch(headless=True)
            context = await browser.new_context()
            
            for i, url in enumerate(media_page_urls[:10]):  # Limitar a las primeras 10 para ejemplo
                try:
                    page = await context.new_page()
                    await page.goto(url, wait_until='domcontentloaded', timeout=30000)
                    await page.wait_for_timeout(2000)
                    
                    # Buscar imÃ¡genes de alta calidad
                    img_urls = await page.evaluate("""
                        () => {
                            const urls = new Set();
                            
                            // Buscar imÃ¡genes de alta calidad
                            const images = document.querySelectorAll('img[src*="pbs.twimg.com"]');
                            images.forEach(img => {
                                if (img.src && (img.src.includes('jpg') || img.src.includes('png') || img.src.includes('webp'))) {
                                    // Convertir a alta calidad
                                    let highQualityUrl = img.src;
                                    if (highQualityUrl.includes('?')) {
                                        highQualityUrl = highQualityUrl.split('?')[0] + '?format=jpg&name=large';
                                    }
                                    urls.add(highQualityUrl);
                                }
                            });
                            
                            // Buscar videos
                            const videos = document.querySelectorAll('video[src], source[src]');
                            videos.forEach(video => {
                                if (video.src) {
                                    urls.add(video.src);
                                }
                            });
                            
                            return Array.from(urls);
                        }
                    """)
                    
                    direct_urls.extend(img_urls)
                    await page.close()
                    
                    print(f"   Procesada pÃ¡gina {i+1}/{len(media_page_urls[:10])}")
                    
                except Exception as e:
                    print(f"âš ï¸  Error procesando {url}: {e}")
                    continue
            
            await browser.close()
        
        # Eliminar duplicados
        direct_urls = list(set(direct_urls))
        print(f"ğŸ”— URLs directas obtenidas: {len(direct_urls)}")
        return direct_urls
    
    async def _download_media_files(self, media_page_urls, username, source_url):
        """Descarga los archivos de medios"""
        if not media_page_urls:
            print("âŒ No hay URLs para procesar")
            return
        
        # Obtener URLs directas
        direct_urls = await self._get_actual_media_urls(media_page_urls)
        
        if not direct_urls:
            print("âŒ No se pudieron extraer URLs directas")
            return
        
        # Crear directorio de sesiÃ³n
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        session_dir = self.download_dir / f"{username}_{timestamp}"
        session_dir.mkdir(exist_ok=True)
        
        print(f"ğŸ’¾ Descargando {len(direct_urls)} archivos en: {session_dir}")
        
        downloaded = 0
        failed = 0
        
        for i, url in enumerate(direct_urls, 1):
            try:
                print(f"â¬‡ï¸  [{i}/{len(direct_urls)}] {url[:60]}...")
                
                # Descargar archivo
                response = self.session.get(url, timeout=30, stream=True)
                response.raise_for_status()
                
                # Generar nombre de archivo
                filename = self._generate_filename_from_url(url, i)
                file_path = session_dir / filename
                
                # Guardar archivo
                with open(file_path, 'wb') as f:
                    for chunk in response.iter_content(chunk_size=8192):
                        f.write(chunk)
                
                size_mb = file_path.stat().st_size / (1024 * 1024)
                print(f"âœ… {filename} ({size_mb:.2f} MB)")
                downloaded += 1
                
                # PequeÃ±a pausa para no sobrecargar el servidor
                await asyncio.sleep(0.5)
                
            except Exception as e:
                print(f"âŒ Error descargando {url}: {e}")
                failed += 1
                continue
        
        # Crear log de la sesiÃ³n
        self._create_session_log(session_dir, {
            'source_url': source_url,
            'username': username,
            'timestamp': timestamp,
            'media_page_urls': len(media_page_urls),
            'direct_urls_found': len(direct_urls),
            'downloaded': downloaded,
            'failed': failed,
            'downloaded_urls': direct_urls
        })
        
        print(f"ğŸ“Š Descarga completada: {downloaded} exitosos, {failed} fallidos")
        print(f"ğŸ“‚ Archivos guardados en: {session_dir}")
    
    def _extract_username_from_url(self, url):
        """Extrae el nombre de usuario de la URL"""
        try:
            parts = url.split('/')
            for i, part in enumerate(parts):
                if part in ['x.com', 'twitter.com'] and i + 1 < len(parts):
                    return parts[i + 1]
            return 'unknown_user'
        except:
            return 'unknown_user'
    
    def _generate_filename_from_url(self, url, index):
        """Genera nombre de archivo apropiado"""
        try:
            parsed = urlparse(url)
            filename = os.path.basename(parsed.path)
            
            if not filename or '.' not in filename:
                # Determinar extensiÃ³n por URL
                if any(fmt in url.lower() for fmt in ['jpg', 'jpeg']):
                    ext = '.jpg'
                elif 'png' in url.lower():
                    ext = '.png'
                elif 'webp' in url.lower():
                    ext = '.webp'
                elif 'mp4' in url.lower():
                    ext = '.mp4'
                else:
                    ext = '.bin'
                
                filename = f"media_{index:04d}{ext}"
            
            # Limpiar nombre de archivo
            filename = re.sub(r'[<>:"/\\|?*]', '_', filename)
            return filename
            
        except:
            return f"media_{index:04d}.bin"
    
    def _create_session_log(self, session_dir, data):
        """Crea archivo de log de la sesiÃ³n"""
        log_file = session_dir / 'download_session.json'
        with open(log_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2, ensure_ascii=False)
        print(f"ğŸ“‹ Log creado: {log_file}")

async def main():
    """FunciÃ³n principal"""
    # URL del perfil de medios de X
    profile_url = "https://x.com/milewskaja_nat/media"
    
    print("ğŸ¬ X Media Downloader Automation")
    print("=" * 60)
    print(f"ğŸ¯ URL objetivo: {profile_url}")
    print("âš ï¸  NOTA: Este script requiere que tengas una sesiÃ³n activa en X")
    print("   AsegÃºrate de estar logueado en tu navegador antes de ejecutar")
    print()
    
    # Crear instancia del descargador
    downloader = XMediaDownloaderAutomation()
    
    # Ejecutar automatizaciÃ³n
    await downloader.extract_and_download_media(profile_url)
    
    print()
    print("ğŸ AutomatizaciÃ³n completada!")
    print(f"ğŸ“‚ Revisa tu directorio: {downloader.download_dir}")

if __name__ == "__main__":
    asyncio.run(main())
